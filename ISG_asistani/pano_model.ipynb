{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dffdaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.4.8 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.217  Python-3.13.7 torch-2.9.0+cpu CPU (AMD Ryzen 7 4800H with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\User\\Desktop\\fabrika\\dataset_pano, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=pano_denetim_v12, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=6, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\User\\runs\\classify\\pano_denetim_v12, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Desktop\\fabrika\\dataset_pano\\train... found 2397 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Desktop\\fabrika\\dataset_pano\\val... found 160 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
      "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 201.955.3 MB/s, size: 17.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Desktop\\fabrika\\dataset_pano\\train... 2397 images, 0 corrupt: 100% ━━━━━━━━━━━━ 2397/2397 3.6Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 144.328.5 MB/s, size: 17.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\fabrika\\dataset_pano\\val... 160 images, 0 corrupt: 100% ━━━━━━━━━━━━ 160/160 187.4Kit/s 0.0s\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\User\\runs\\classify\\pano_denetim_v12\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       1/50         0G     0.2389         13        224: 100% ━━━━━━━━━━━━ 150/150 2.2it/s 1:090.4sss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 5/5 3.1it/s 1.6s0.4s\n",
      "                   all      0.975          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       2/50         0G     0.1637         13        224: 100% ━━━━━━━━━━━━ 150/150 2.4it/s 1:040.4sss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 5/5 3.6it/s 1.4s0.4s\n",
      "                   all      0.956          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       3/50         0G     0.1561         13        224: 100% ━━━━━━━━━━━━ 150/150 2.5it/s 1:010.4sss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 5/5 3.8it/s 1.3s0.3s\n",
      "                   all      0.956          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       4/50         0G     0.1551         13        224: 100% ━━━━━━━━━━━━ 150/150 2.4it/s 1:020.4sss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 5/5 3.2it/s 1.6s0.4s\n",
      "                   all      0.956          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       5/50         0G     0.1509         13        224: 100% ━━━━━━━━━━━━ 150/150 2.3it/s 1:050.4sss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 5/5 3.8it/s 1.3s0.4s\n",
      "                   all      0.956          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       6/50         0G     0.1479         13        224: 100% ━━━━━━━━━━━━ 150/150 2.5it/s 59.3s0.3ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 5/5 3.7it/s 1.4s0.3s\n",
      "                   all      0.956          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       7/50         0G     0.1506         13        224: 100% ━━━━━━━━━━━━ 150/150 2.5it/s 1:000.4sss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 5/5 3.4it/s 1.5s0.4s\n",
      "                   all      0.956          1\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 6 epochs. Best results observed at epoch 1, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=6) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "7 epochs completed in 0.125 hours.\n",
      "Optimizer stripped from C:\\Users\\User\\runs\\classify\\pano_denetim_v12\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from C:\\Users\\User\\runs\\classify\\pano_denetim_v12\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating C:\\Users\\User\\runs\\classify\\pano_denetim_v12\\weights\\best.pt...\n",
      "Ultralytics 8.3.217  Python-3.13.7 torch-2.9.0+cpu CPU (AMD Ryzen 7 4800H with Radeon Graphics)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\User\\Desktop\\fabrika\\dataset_pano\\train... found 2397 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m C:\\Users\\User\\Desktop\\fabrika\\dataset_pano\\val... found 160 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ━━━━━━━━━━━━ 5/5 4.6it/s 1.1s0.3s\n",
      "                   all      0.975          1\n",
      "Speed: 0.0ms preprocess, 4.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\User\\runs\\classify\\pano_denetim_v12\u001b[0m\n",
      "\n",
      "✅ Eğitim Tamamlandı!\n",
      "En iyi model şurada: runs/classify/pano_denetim_v1/weights/best.pt\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. Model ve Veri Yolu\n",
    "dataset_path = r\"C:\\Users\\User\\Desktop\\fabrika\\dataset_pano\"\n",
    "model = YOLO('yolov8n-cls.pt') # Nano model (hızlı ve hafif)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 2. Gelişmiş Eğitim Ayarları\n",
    "    results = model.train(\n",
    "        data=dataset_path,\n",
    "        epochs=50,          # Maksimum 100 tur (Early stopping bunu kesecektir)\n",
    "        imgsz=224,\n",
    "        batch=16,\n",
    "        \n",
    "        # --- EARLY STOPPING & CHECKPOINT ---\n",
    "        patience=6,         # 10 epoch boyunca gelişme olmazsa eğitimi DURDUR\n",
    "        save=True,           # Checkpoint'leri otomatik kaydet (best.pt, last.pt)\n",
    "        save_period=5,       # Her 5 epoch'ta bir yedek model kaydet (isteğe bağlı)\n",
    "        \n",
    "        # --- OPTİMİZASYON ---\n",
    "        optimizer='AdamW',   # Daha kararlı bir öğrenme için\n",
    "        lr0=0.001,           # Başlangıç öğrenme oranı\n",
    "        name='pano_denetim_v1'\n",
    "    )\n",
    "\n",
    "    print(\"\\n✅ Eğitim Tamamlandı!\")\n",
    "    print(\"En iyi model şurada: runs/classify/pano_denetim_v1/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ce956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Analiz tamamlandı! 'denetim_sonucu.mp4' dosyasını kontrol edebilirsin.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. Modeli ve Videoyu Tanımla\n",
    "MODEL_PATH = r\"C:\\Users\\User\\runs\\classify\\pano_denetim_v12\\weights\\best.pt\"\n",
    "cap = cv2.VideoCapture(r\"test.mp4\")\n",
    "\n",
    "# Çıktı Videosu Ayarları\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('denetim_sonucu.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "model = YOLO(MODEL_PATH)\n",
    "PANO_PTS = np.float32([[200, 620], [420, 660], [430, 780], [220, 750]])\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # Perspektif Kırpma\n",
    "    dst_pts = np.float32([[0, 0], [224, 0], [224, 224], [0, 224]])\n",
    "    matrix = cv2.getPerspectiveTransform(PANO_PTS, dst_pts)\n",
    "    pano_crop = cv2.warpPerspective(frame, matrix, (224, 224))\n",
    "    \n",
    "    # Tahmin\n",
    "    results = model.predict(pano_crop, verbose=False)[0]\n",
    "    label = results.names[results.probs.top1]\n",
    "    conf = results.probs.top1conf.item()\n",
    "\n",
    "    # Görselleştirme\n",
    "    color = (0, 255, 0) if label == \"kapali\" else (0, 0, 255)\n",
    "    cv2.polylines(frame, [PANO_PTS.astype(np.int32)], True, color, 3)\n",
    "    cv2.putText(frame, f\"{label} %{conf:.2f}\", (int(PANO_PTS[0][0]), int(PANO_PTS[0][1]-10)), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    # Videoya yaz\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"✅ Analiz tamamlandı! 'denetim_sonucu.mp4' dosyasını kontrol edebilirsin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02bb2675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Analiz tamamlandı! 'denetim_sonucu.mp4' dosyasını kontrol edebilirsin.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. Modeli ve Videoyu Tanımla\n",
    "MODEL_PATH = r\"C:\\Users\\User\\runs\\classify\\pano_denetim_v12\\weights\\best.pt\"\n",
    "cap = cv2.VideoCapture(r\"test2.mp4\")\n",
    "\n",
    "# Çıktı Videosu Ayarları\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('denetim_sonucu2.mp4', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "model = YOLO(MODEL_PATH)\n",
    "PANO_PTS = np.float32([[200, 620], [420, 660], [430, 780], [220, 750]])\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    # Perspektif Kırpma\n",
    "    dst_pts = np.float32([[0, 0], [224, 0], [224, 224], [0, 224]])\n",
    "    matrix = cv2.getPerspectiveTransform(PANO_PTS, dst_pts)\n",
    "    pano_crop = cv2.warpPerspective(frame, matrix, (224, 224))\n",
    "    \n",
    "    # Tahmin\n",
    "    results = model.predict(pano_crop, verbose=False)[0]\n",
    "    label = results.names[results.probs.top1]\n",
    "    conf = results.probs.top1conf.item()\n",
    "\n",
    "    # Görselleştirme\n",
    "    color = (0, 255, 0) if label == \"kapali\" else (0, 0, 255)\n",
    "    cv2.polylines(frame, [PANO_PTS.astype(np.int32)], True, color, 3)\n",
    "    cv2.putText(frame, f\"{label} %{conf:.2f}\", (int(PANO_PTS[0][0]), int(PANO_PTS[0][1]-10)), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    # Videoya yaz\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"✅ Analiz tamamlandı! 'denetim_sonucu.mp4' dosyasını kontrol edebilirsin.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff836ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model başarıyla kopyalandı: C:\\Users\\User\\Desktop\\fabrika_pano_modeli.pt\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Kaynak ve hedef yollar\n",
    "kaynak = r\"C:\\Users\\User\\runs\\classify\\pano_denetim_v12\\weights\\best.pt\"\n",
    "masaustu = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"fabrika_pano_modeli.pt\")\n",
    "\n",
    "try:\n",
    "    shutil.copy(kaynak, masaustu)\n",
    "    print(f\"✅ Model başarıyla kopyalandı: {masaustu}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ Dosya bulunamadı, lütfen yolu kontrol et.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
